{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-11T06:52:38.950597Z",
     "iopub.status.busy": "2022-04-11T06:52:38.950001Z",
     "iopub.status.idle": "2022-04-11T06:52:38.973286Z",
     "shell.execute_reply": "2022-04-11T06:52:38.972642Z",
     "shell.execute_reply.started": "2022-04-11T06:52:38.950474Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"data\" \n",
    "seed = 46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports and random seeding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import BertTokenizer\n",
    "#BertTokenizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:52:38.974823Z",
     "iopub.status.busy": "2022-04-11T06:52:38.974472Z",
     "iopub.status.idle": "2022-04-11T06:52:41.618903Z",
     "shell.execute_reply": "2022-04-11T06:52:41.618159Z",
     "shell.execute_reply.started": "2022-04-11T06:52:38.974785Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "np.random.RandomState(seed)\n",
    "\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(seed)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import BertTokenizer, BertConfig, BertForTokenClassification, AutoTokenizer, AutoConfig\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, recall_score, confusion_matrix, balanced_accuracy_score\n",
    "\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenization and label expansion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:52:41.620511Z",
     "iopub.status.busy": "2022-04-11T06:52:41.620291Z",
     "iopub.status.idle": "2022-04-11T06:52:42.244648Z",
     "shell.execute_reply": "2022-04-11T06:52:42.243885Z",
     "shell.execute_reply.started": "2022-04-11T06:52:41.620486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ner_tags</th>\n",
       "      <th>ner_ids</th>\n",
       "      <th>tokens</th>\n",
       "      <th>space_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[O, GPE, O, O, O, O, O, O, LOC, O, O, O, O, O,...</td>\n",
       "      <td>[0, 3, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[În, România, ,, ca, de, altfel, în, întreaga,...</td>\n",
       "      <td>[True, False, True, True, True, True, True, Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[O, O, O, DATETIME, DATETIME, O, O, O, O, O, O...</td>\n",
       "      <td>[0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 13, 13, 1...</td>\n",
       "      <td>[Se, estimează, că, în, prezent, acestea, sunt...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[O, O, O, O, O, NUMERIC, O, O, O, PERSON, O, P...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 13, 0, 0, 0, 1, 0, 1, 0, 0, 1,...</td>\n",
       "      <td>[Cartea, cuprinde, o, suită, de, 115, texte-re...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, DATETIME, DA...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 0]</td>\n",
       "      <td>[Bursele, pentru, proiecte, ArtsLink, -, terme...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Aplicația, informațională, este, însoțită, de...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           ner_tags  \\\n",
       "0      0  [O, GPE, O, O, O, O, O, O, LOC, O, O, O, O, O,...   \n",
       "1      1  [O, O, O, DATETIME, DATETIME, O, O, O, O, O, O...   \n",
       "2      2  [O, O, O, O, O, NUMERIC, O, O, O, PERSON, O, P...   \n",
       "3      3  [O, O, O, O, O, O, O, O, O, O, O, DATETIME, DA...   \n",
       "4      4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                             ner_ids  \\\n",
       "0  [0, 3, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 13, 13, 1...   \n",
       "2  [0, 0, 0, 0, 0, 13, 0, 0, 0, 1, 0, 1, 0, 0, 1,...   \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 0]   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [În, România, ,, ca, de, altfel, în, întreaga,...   \n",
       "1  [Se, estimează, că, în, prezent, acestea, sunt...   \n",
       "2  [Cartea, cuprinde, o, suită, de, 115, texte-re...   \n",
       "3  [Bursele, pentru, proiecte, ArtsLink, -, terme...   \n",
       "4  [Aplicația, informațională, este, însoțită, de...   \n",
       "\n",
       "                                         space_after  \n",
       "0  [True, False, True, True, True, True, True, Tr...  \n",
       "1  [True, True, True, True, True, True, True, Tru...  \n",
       "2  [True, True, True, True, True, True, True, Tru...  \n",
       "3  [True, True, True, True, True, True, True, Tru...  \n",
       "4  [True, True, True, True, True, True, True, Tru...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_json(f\"{data_path}/train.json\")\n",
    "\n",
    "# those entries contain invalid tokens, like Romani is tokenized as 'r', 'omani'\n",
    "invalid_tokenization = [27, 1109, 1893, 2545, 3853, 3906, 6043, 6281, 7107, 7458, 8016, 8633, 8683, 8747, 8986, 10062, 10271, 11123, 12042, 12047, 12066]\n",
    "df_train = df_train.drop(df_train.index[invalid_tokenization]).reset_index()\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:52:42.246294Z",
     "iopub.status.busy": "2022-04-11T06:52:42.24602Z",
     "iopub.status.idle": "2022-04-11T06:52:42.305637Z",
     "shell.execute_reply": "2022-04-11T06:52:42.304766Z",
     "shell.execute_reply.started": "2022-04-11T06:52:42.246255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>space_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Cazul, tinerei, agresate, de, agenții, de, pa...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\\n, Scandal, la, Carrefour, Braşov, :, Unde, ...</td>\n",
       "      <td>[False, True, True, True, False, True, True, T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[De, ce, câștigă, Facebook, și, când, utilizat...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[EXCLUSIV, !, Tupeu, fără, margini, !, Profi, ...</td>\n",
       "      <td>[False, True, True, True, False, True, True, T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[PROFI, ,, în, mijlocul, unui, scandal, !, Rep...</td>\n",
       "      <td>[False, True, True, True, True, False, True, T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [Cazul, tinerei, agresate, de, agenții, de, pa...   \n",
       "1  [\\n, Scandal, la, Carrefour, Braşov, :, Unde, ...   \n",
       "2  [De, ce, câștigă, Facebook, și, când, utilizat...   \n",
       "3  [EXCLUSIV, !, Tupeu, fără, margini, !, Profi, ...   \n",
       "4  [PROFI, ,, în, mijlocul, unui, scandal, !, Rep...   \n",
       "\n",
       "                                         space_after  \n",
       "0  [True, True, True, True, True, True, True, Fal...  \n",
       "1  [False, True, True, True, False, True, True, T...  \n",
       "2  [True, True, True, True, True, True, True, Tru...  \n",
       "3  [False, True, True, True, False, True, True, T...  \n",
       "4  [False, True, True, True, True, False, True, T...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluation = pd.read_json(f\"{data_path}/test.json\")\n",
    "df_evaluation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:52:42.307736Z",
     "iopub.status.busy": "2022-04-11T06:52:42.307434Z",
     "iopub.status.idle": "2022-04-11T06:52:42.314729Z",
     "shell.execute_reply": "2022-04-11T06:52:42.314161Z",
     "shell.execute_reply.started": "2022-04-11T06:52:42.307692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluation[\"tokens\"].map(len).max() # max 99 tokens, so ~ 100 input size for BERT should be ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:52:42.316317Z",
     "iopub.status.busy": "2022-04-11T06:52:42.315523Z",
     "iopub.status.idle": "2022-04-11T06:52:42.529739Z",
     "shell.execute_reply": "2022-04-11T06:52:42.528954Z",
     "shell.execute_reply.started": "2022-04-11T06:52:42.316277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def has_invalid_chars(sentences):\n",
    "    bad_chars = set([\"ţ\", \"ş\", \"Ş\", \"Ţ\"])\n",
    "    for sentence in sentences:\n",
    "        for token in sentence:\n",
    "            for letter in token:\n",
    "                if letter in bad_chars:\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "has_invalid_chars(df_train[\"tokens\"]), has_invalid_chars(df_evaluation[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:52:42.531162Z",
     "iopub.status.busy": "2022-04-11T06:52:42.530863Z",
     "iopub.status.idle": "2022-04-11T06:53:02.731449Z",
     "shell.execute_reply": "2022-04-11T06:53:02.72842Z",
     "shell.execute_reply.started": "2022-04-11T06:52:42.53113Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.732324Z",
     "iopub.status.idle": "2022-04-11T06:53:02.732663Z",
     "shell.execute_reply": "2022-04-11T06:53:02.732502Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.732478Z"
    }
   },
   "outputs": [],
   "source": [
    "def sanitize_chars(text):\n",
    "    return text.replace(\"ţ\", \"ț\").replace(\"ş\", \"ș\").replace(\"Ţ\", \"Ț\").replace(\"Ş\", \"Ș\")\n",
    "\n",
    "def rejoin(tokens, space_after):\n",
    "    l = []\n",
    "    for t, s in zip(tokens, space_after):\n",
    "        l.append(t)\n",
    "        if s: l.append(' ')\n",
    "    return sanitize_chars(''.join(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.734268Z",
     "iopub.status.idle": "2022-04-11T06:53:02.73503Z",
     "shell.execute_reply": "2022-04-11T06:53:02.734784Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.734755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = [set(l) for l in df_train[\"ner_ids\"]]\n",
    "labels_cnt = len(unique_labels[0].union(*unique_labels[1:]))\n",
    "labels_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.736524Z",
     "iopub.status.idle": "2022-04-11T06:53:02.737166Z",
     "shell.execute_reply": "2022-04-11T06:53:02.73691Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.736881Z"
    }
   },
   "outputs": [],
   "source": [
    "EXTRA_LABEL = labels_cnt\n",
    "\n",
    "def propagate_labels_to_bert(bert_tokens, premade_tokens, known_labels, dbg_idx=None):\n",
    "    assert len(premade_tokens) == len(known_labels)\n",
    "    \n",
    "    labels = [EXTRA_LABEL for _ in range(len(bert_tokens))]\n",
    "    reconstruction_array = []\n",
    "    \n",
    "    try:\n",
    "        bert_tokens_idx = 1\n",
    "        premade_tokens_idx = 0\n",
    "\n",
    "        while bert_tokens_idx < len(bert_tokens) and premade_tokens_idx < len(premade_tokens):\n",
    "            our_tk = premade_tokens[premade_tokens_idx]\n",
    "            total_eaten = 0\n",
    "\n",
    "            how_many_expanded = 0\n",
    "\n",
    "            while total_eaten < len(our_tk):\n",
    "                their_tk = bert_tokens[bert_tokens_idx]\n",
    "                their_tk_strip = their_tk.replace(\"##\", \"\")\n",
    "                labels[bert_tokens_idx] = known_labels[premade_tokens_idx]\n",
    "\n",
    "                # print(bert_tokens_idx, their_tk, our_tk, known_labels[premade_tokens_idx], \"k =\", total_eaten)\n",
    "\n",
    "                total_eaten += len(their_tk_strip)\n",
    "                bert_tokens_idx += 1\n",
    "\n",
    "                how_many_expanded += 1\n",
    "\n",
    "            reconstruction_array.append(how_many_expanded)\n",
    "\n",
    "            premade_tokens_idx += 1\n",
    "    except Exception as e:\n",
    "        print(\"Invalid tokenization at\", dbg_idx, str(e))\n",
    "        \n",
    "        # Broken entry, just set 0 everywhere. TODO: fix this later.\n",
    "        labels = [0 for _ in range(len(premade_tokens))]\n",
    "        reconstruction_array = [1 for _ in range(len(premade_tokens))]\n",
    "\n",
    "    return labels, reconstruction_array\n",
    "\n",
    "def reconstruct_labels_from_bert(bert_labels, reconstruction_array):\n",
    "    labels = []\n",
    "    bert_idx = 1\n",
    "    \n",
    "    for v in reconstruction_array:\n",
    "        if v == 0 or bert_idx >= len(bert_labels):\n",
    "            break\n",
    "            \n",
    "        #assert len(set(bert_labels[bert_idx:bert_idx+v])) == 1\n",
    "        #print(set(bert_labels[bert_idx:bert_idx+v]))\n",
    "        \n",
    "        labels.append(bert_labels[bert_idx])\n",
    "        bert_idx += v\n",
    "        \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.738687Z",
     "iopub.status.idle": "2022-04-11T06:53:02.739068Z",
     "shell.execute_reply": "2022-04-11T06:53:02.738898Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.738873Z"
    }
   },
   "outputs": [],
   "source": [
    "first_sentence = rejoin(df_train[\"tokens\"][0], df_train[\"space_after\"][0])\n",
    "first_sentence_encoding = bert_tokenizer([first_sentence])[0].tokens\n",
    "\n",
    "bert_labels, reconstruction_array = propagate_labels_to_bert(first_sentence_encoding, df_train[\"tokens\"][0], df_train[\"ner_ids\"][0])\n",
    "# adding some 0s at the end won't change anything\n",
    "assert reconstruct_labels_from_bert(bert_labels + [0], reconstruction_array + [0, 0, 0]) == df_train[\"ner_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.740803Z",
     "iopub.status.idle": "2022-04-11T06:53:02.741154Z",
     "shell.execute_reply": "2022-04-11T06:53:02.740998Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.740972Z"
    }
   },
   "outputs": [],
   "source": [
    "class PerfTimer:\n",
    "    def __init__(self):\n",
    "        self.start_t = 0\n",
    "        \n",
    "    def start(self):\n",
    "        self.start_t = time.time_ns()\n",
    "         \n",
    "    def stop(self, msg = None):\n",
    "        elapsed = time.time_ns() - self.start_t\n",
    "        if msg is not None:\n",
    "            print(f\"{msg}: took {elapsed} ns.\")\n",
    "        else:\n",
    "            print(f\"Elapsed {elapsed} ns.\")\n",
    "        return elapsed\n",
    "\n",
    "def perf_check_tokenize(sentences, labels, tokenizer):\n",
    "    full_sentences = [rejoin(tokens, space_after) for tokens, space_after in sentences]\n",
    "    \n",
    "    timer = PerfTimer()\n",
    "    \n",
    "    timer.start()\n",
    "    tokenized_a = tokenizer(full_sentences)\n",
    "    for i in range(len(full_sentences)):\n",
    "        propagate_labels_to_bert(tokenized_a[i].tokens, sentences[i][0], labels[i])\n",
    "    time_a = timer.stop('Tokenize the whole dataset. (A)')\n",
    "    \n",
    "    timer.start()\n",
    "    tokenized_b = []\n",
    "    for sentence in full_sentences:\n",
    "        tokenized_b.append(tokenizer(sentence))\n",
    "    for i in range(len(full_sentences)):\n",
    "        propagate_labels_to_bert(tokenized_b[i].tokens(), sentences[i][0], labels[i])\n",
    "    time_b = timer.stop('Tokenize each sentence. (B)')\n",
    "        \n",
    "    timer.start()\n",
    "    tokenized_c = []\n",
    "    for tokens, space_after in sentences:\n",
    "        to_add = []\n",
    "        for token in tokens:\n",
    "            to_add.append(tokenizer(token))\n",
    "        tokenized_c.append(to_add)\n",
    "    time_c = timer.stop('Tokenize each word. (C)')\n",
    "    \n",
    "    m = max(time_a, time_b, time_c)\n",
    "    print(f\"Ratio to max {time_a/m:.4f}/{time_b/m:.4f}/{time_c/m:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.742256Z",
     "iopub.status.idle": "2022-04-11T06:53:02.742919Z",
     "shell.execute_reply": "2022-04-11T06:53:02.742755Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.742707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize the whole dataset. (A): took 89005400 ns.\n",
      "Tokenize each sentence. (B): took 239512600 ns.\n",
      "Tokenize each word. (C): took 2768025200 ns.\n",
      "Ratio to max 0.0322/0.0865/1.0000\n"
     ]
    }
   ],
   "source": [
    "perf_check_tokenize(list(zip(df_train[\"tokens\"][:1000], df_train[\"space_after\"][:1000])), df_train[\"ner_ids\"][:1000], bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.744299Z",
     "iopub.status.idle": "2022-04-11T06:53:02.744668Z",
     "shell.execute_reply": "2022-04-11T06:53:02.744508Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.744485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ner_tags</th>\n",
       "      <th>ner_ids</th>\n",
       "      <th>tokens</th>\n",
       "      <th>space_after</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[O, GPE, O, O, O, O, O, O, LOC, O, O, O, O, O,...</td>\n",
       "      <td>[0, 3, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[În, România, ,, ca, de, altfel, în, întreaga,...</td>\n",
       "      <td>[True, False, True, True, True, True, True, Tr...</td>\n",
       "      <td>În România, ca de altfel în întreaga Europă, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[O, O, O, DATETIME, DATETIME, O, O, O, O, O, O...</td>\n",
       "      <td>[0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 13, 13, 1...</td>\n",
       "      <td>[Se, estimează, că, în, prezent, acestea, sunt...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>Se estimează că în prezent acestea sunt utiliz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[O, O, O, O, O, NUMERIC, O, O, O, PERSON, O, P...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 13, 0, 0, 0, 1, 0, 1, 0, 0, 1,...</td>\n",
       "      <td>[Cartea, cuprinde, o, suită, de, 115, texte-re...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>Cartea cuprinde o suită de 115 texte-remember ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, DATETIME, DA...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 0]</td>\n",
       "      <td>[Bursele, pentru, proiecte, ArtsLink, -, terme...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>Bursele pentru proiecte ArtsLink - termen limi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Aplicația, informațională, este, însoțită, de...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>Aplicația informațională este însoțită de un s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           ner_tags  \\\n",
       "0      0  [O, GPE, O, O, O, O, O, O, LOC, O, O, O, O, O,...   \n",
       "1      1  [O, O, O, DATETIME, DATETIME, O, O, O, O, O, O...   \n",
       "2      2  [O, O, O, O, O, NUMERIC, O, O, O, PERSON, O, P...   \n",
       "3      3  [O, O, O, O, O, O, O, O, O, O, O, DATETIME, DA...   \n",
       "4      4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                             ner_ids  \\\n",
       "0  [0, 3, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 13, 13, 1...   \n",
       "2  [0, 0, 0, 0, 0, 13, 0, 0, 0, 1, 0, 1, 0, 0, 1,...   \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 0]   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [În, România, ,, ca, de, altfel, în, întreaga,...   \n",
       "1  [Se, estimează, că, în, prezent, acestea, sunt...   \n",
       "2  [Cartea, cuprinde, o, suită, de, 115, texte-re...   \n",
       "3  [Bursele, pentru, proiecte, ArtsLink, -, terme...   \n",
       "4  [Aplicația, informațională, este, însoțită, de...   \n",
       "\n",
       "                                         space_after  \\\n",
       "0  [True, False, True, True, True, True, True, Tr...   \n",
       "1  [True, True, True, True, True, True, True, Tru...   \n",
       "2  [True, True, True, True, True, True, True, Tru...   \n",
       "3  [True, True, True, True, True, True, True, Tru...   \n",
       "4  [True, True, True, True, True, True, True, Tru...   \n",
       "\n",
       "                                            sentence  \n",
       "0  În România, ca de altfel în întreaga Europă, s...  \n",
       "1  Se estimează că în prezent acestea sunt utiliz...  \n",
       "2  Cartea cuprinde o suită de 115 texte-remember ...  \n",
       "3  Bursele pentru proiecte ArtsLink - termen limi...  \n",
       "4  Aplicația informațională este însoțită de un s...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"sentence\"] = df_train.apply(lambda x: rejoin(x['tokens'], x['space_after']), axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.745701Z",
     "iopub.status.idle": "2022-04-11T06:53:02.74604Z",
     "shell.execute_reply": "2022-04-11T06:53:02.745894Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.745872Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_TOKENS = 240\n",
    "BERT_IN_TOKENS = MAX_TOKENS + 16\n",
    "BERT_PAD = '[PAD]'\n",
    "\n",
    "def fixed_sz(l, sz, elem):\n",
    "    if len(l) >= sz:\n",
    "        return l[:sz] \n",
    "    \n",
    "    return l + [elem for _ in range(sz - len(l))]\n",
    "\n",
    "def bert_encode(tokenizer, tokens, space_after, labels=None, trim=MAX_TOKENS):\n",
    "    sentences = [rejoin(x[:trim], y[:trim]) for x, y in zip(tokens, space_after)]\n",
    "    \n",
    "    bert_encodings = tokenizer(sentences)\n",
    "    bert_labels = []\n",
    "    bert_reconstruction = []\n",
    "    \n",
    "    if labels is not None:\n",
    "        bert_labels_and_reconstruction = [propagate_labels_to_bert(bert_encodings[i].tokens, tokens[i][:trim], labels[i][:trim], dbg_idx=i) for i in range(len(sentences))]\n",
    "        bert_labels = [x[0] for x in bert_labels_and_reconstruction]\n",
    "        bert_reconstruction = [x[1] for x in bert_labels_and_reconstruction]\n",
    "        \n",
    "    return bert_encodings, bert_labels, bert_reconstruction\n",
    "  \n",
    "def bert_decode(bert_labels, reconstruction_arrays):\n",
    "    return [reconstruct_labels_from_bert(labels_i, reconstruction_array_i) for labels_i, reconstruction_array_i in zip(bert_labels, reconstruction_arrays)]\n",
    "\n",
    "assert fixed_sz([1, 2, 3], 4, 0) == [1, 2, 3, 0]\n",
    "assert fixed_sz([1, 2, 3], 3, 0) == [1, 2, 3]\n",
    "assert fixed_sz([1, 2, 3], 2, 0) == [1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert dataset to tensors and prepare loaders and model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.747243Z",
     "iopub.status.idle": "2022-04-11T06:53:02.747584Z",
     "shell.execute_reply": "2022-04-11T06:53:02.747434Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.7474Z"
    }
   },
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, encodings, all_labels, all_reconstructions):\n",
    "        self.all_reconstructions = [torch.as_tensor(fixed_sz(all_reconstructions[i], BERT_IN_TOKENS, 0)) for i in range(len(all_labels))]\n",
    "        self.all_tokens = [fixed_sz(encodings[i].tokens, BERT_IN_TOKENS, BERT_PAD) for i in range(len(all_labels))]\n",
    "        self.all_ids = [torch.as_tensor(fixed_sz(encodings[i].ids, BERT_IN_TOKENS, 0)) for i in range(len(all_labels))]\n",
    "        self.all_attention_mask = [torch.as_tensor(fixed_sz(encodings[i].attention_mask, BERT_IN_TOKENS, 0)) for i in range(len(all_labels))]\n",
    "        self.all_labels = [torch.as_tensor(fixed_sz(labels, BERT_IN_TOKENS, EXTRA_LABEL)) for labels in all_labels]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'ids': self.all_ids[index],\n",
    "            'attention_mask': self.all_attention_mask[index],\n",
    "            'reconstruction': self.all_reconstructions[index],\n",
    "            'tokens': self.all_tokens[index],\n",
    "            'labels': self.all_labels[index],\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.749495Z",
     "iopub.status.idle": "2022-04-11T06:53:02.750017Z",
     "shell.execute_reply": "2022-04-11T06:53:02.749815Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.749785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid tokenization at 11004 list index out of range\n",
      "BERT Tokenization: took 1534058500 ns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1534058500"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = PerfTimer()\n",
    "timer.start()\n",
    "bert_encodings, bert_labels, bert_reconstruction = bert_encode(bert_tokenizer, df_train[\"tokens\"], df_train[\"space_after\"], df_train[\"ner_ids\"])\n",
    "timer.stop(\"BERT Tokenization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.751108Z",
     "iopub.status.idle": "2022-04-11T06:53:02.751422Z",
     "shell.execute_reply": "2022-04-11T06:53:02.751282Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.751261Z"
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: For some reason len(bert_encodings) always returns 3 (some strange logic inside), \n",
    "# so pleause use len() on other objects if you want to get the number of rows\n",
    "X = [(bert_encodings[i], bert_labels[i], bert_reconstruction[i]) for i in range(len(bert_labels))]\n",
    "y = df_train[\"ner_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.752829Z",
     "iopub.status.idle": "2022-04-11T06:53:02.75339Z",
     "shell.execute_reply": "2022-04-11T06:53:02.753214Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.75319Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=seed, shuffle=True)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.75435Z",
     "iopub.status.idle": "2022-04-11T06:53:02.755008Z",
     "shell.execute_reply": "2022-04-11T06:53:02.75483Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.754809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid tokenization at 146 list index out of range\n",
      "Invalid tokenization at 150 list index out of range\n",
      "Invalid tokenization at 151 list index out of range\n",
      "Invalid tokenization at 157 list index out of range\n",
      "Invalid tokenization at 160 list index out of range\n",
      "Invalid tokenization at 164 list index out of range\n",
      "Invalid tokenization at 165 list index out of range\n",
      "Invalid tokenization at 168 list index out of range\n",
      "Invalid tokenization at 169 list index out of range\n",
      "Invalid tokenization at 172 list index out of range\n",
      "Invalid tokenization at 176 list index out of range\n",
      "Invalid tokenization at 179 list index out of range\n",
      "Invalid tokenization at 182 list index out of range\n",
      "Invalid tokenization at 194 list index out of range\n",
      "Invalid tokenization at 196 list index out of range\n",
      "Invalid tokenization at 197 list index out of range\n",
      "Invalid tokenization at 595 list index out of range\n",
      "Invalid tokenization at 630 list index out of range\n",
      "Invalid tokenization at 720 list index out of range\n",
      "Invalid tokenization at 890 list index out of range\n",
      "Invalid tokenization at 945 list index out of range\n",
      "Invalid tokenization at 1001 list index out of range\n",
      "Invalid tokenization at 1019 list index out of range\n",
      "Invalid tokenization at 1036 list index out of range\n",
      "Invalid tokenization at 1118 list index out of range\n",
      "Invalid tokenization at 1221 list index out of range\n",
      "Invalid tokenization at 1253 list index out of range\n",
      "Invalid tokenization at 1329 list index out of range\n",
      "Invalid tokenization at 1498 list index out of range\n",
      "Invalid tokenization at 1571 list index out of range\n",
      "Invalid tokenization at 1616 list index out of range\n",
      "Invalid tokenization at 1621 list index out of range\n",
      "Invalid tokenization at 1698 list index out of range\n",
      "Invalid tokenization at 1710 list index out of range\n",
      "Invalid tokenization at 1750 list index out of range\n",
      "Invalid tokenization at 1772 list index out of range\n",
      "Invalid tokenization at 1779 list index out of range\n",
      "Invalid tokenization at 1832 list index out of range\n",
      "Invalid tokenization at 1855 list index out of range\n",
      "Invalid tokenization at 1958 list index out of range\n",
      "Invalid tokenization at 1988 list index out of range\n",
      "Invalid tokenization at 2095 list index out of range\n",
      "Invalid tokenization at 2259 list index out of range\n",
      "Invalid tokenization at 2327 list index out of range\n",
      "BERT Tokenization (evaluation set): took 246494500 ns.\n"
     ]
    }
   ],
   "source": [
    "timer = PerfTimer()\n",
    "timer.start()\n",
    "zero_labels = [np.zeros(len(df_evaluation[\"tokens\"][i])) for i in range(len(df_evaluation))]\n",
    "bert_encodings, bert_labels, bert_reconstruction = bert_encode(bert_tokenizer, df_evaluation[\"tokens\"], df_evaluation[\"space_after\"], zero_labels)\n",
    "timer.stop(\"BERT Tokenization (evaluation set)\")\n",
    "\n",
    "X_evaluation = [(bert_encodings[i], bert_labels[i], bert_reconstruction[i]) for i in range(len(bert_labels))]\n",
    "y_evaluation = zero_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.756558Z",
     "iopub.status.idle": "2022-04-11T06:53:02.757117Z",
     "shell.execute_reply": "2022-04-11T06:53:02.756882Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.756851Z"
    }
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "def make_dataset(X, y):\n",
    "    bert_encodings = list(map(itemgetter(0), X))\n",
    "    bert_labels = list(map(itemgetter(1), X))\n",
    "    bert_reconstruction = list(map(itemgetter(2), X))\n",
    "    return BERTDataset(bert_encodings, bert_labels, bert_reconstruction)\n",
    "\n",
    "dataset_train = make_dataset(X_train, y_train)\n",
    "dataset_validation = make_dataset(X_val, y_val)\n",
    "dataset_test = make_dataset(X_test, y_test)\n",
    "\n",
    "dataset_evaluation = make_dataset(X_evaluation, y_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 10.497039910176584, 20.243996062992125, 32.162470680218924, 74.40007234581299, 81.57009716438628, 114.10762829403606, 613.9671641791044, 57.80747611017426, 19.242118065300776, 112.11719814663395, 100.77364037236649, 153.14892032762472, 51.39405297351324, 133.688007799805, 121.30875847832498]\n"
     ]
    }
   ],
   "source": [
    "all_ner_ids = df_train[\"ner_ids\"].explode().tolist()\n",
    "\n",
    "import collections\n",
    "counts = collections.OrderedDict(sorted(collections.Counter(all_ner_ids).items()))\n",
    "counts_values = counts.values()\n",
    "max_class = max(counts_values)\n",
    "\n",
    "print([max_class / i for i in counts_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.758202Z",
     "iopub.status.idle": "2022-04-11T06:53:02.758799Z",
     "shell.execute_reply": "2022-04-11T06:53:02.758559Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.758526Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dumitrescustefan/bert-base-romanian-cased-v1 were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dumitrescustefan/bert-base-romanian-cased-v1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(50000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.4, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.4, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.4, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.4, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.4, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.4, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.4, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.4, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.4, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.4, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.4, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.4, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.4, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "configuration = AutoConfig.from_pretrained('dumitrescustefan/bert-base-romanian-cased-v1')\n",
    "configuration.classifier_dropout = 0.4\n",
    "configuration.attention_probs_dropout_prob = 0.4\n",
    "configuration.hidden_dropout_prob = 0.4\n",
    "\n",
    "configuration.num_labels = labels_cnt + 1\n",
    "        \n",
    "model = BertForTokenClassification.from_pretrained(pretrained_model_name_or_path = 'dumitrescustefan/bert-base-romanian-cased-v1', config=configuration)\n",
    "\n",
    "#model = BertForTokenClassification.from_pretrained('dumitrescustefan/bert-base-romanian-cased-v1', num_labels=labels_cnt + 1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.759846Z",
     "iopub.status.idle": "2022-04-11T06:53:02.760158Z",
     "shell.execute_reply": "2022-04-11T06:53:02.760014Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.759993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will be frozen: bert.embeddings.word_embeddings.weight\n",
      "I will be frozen: bert.embeddings.position_embeddings.weight\n",
      "I will be frozen: bert.embeddings.token_type_embeddings.weight\n",
      "I will be frozen: bert.embeddings.LayerNorm.weight\n",
      "I will be frozen: bert.embeddings.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.0.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.0.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.0.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.0.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.0.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.0.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.1.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.1.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.1.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.1.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.1.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.1.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.2.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.2.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.2.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.2.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.2.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.2.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.3.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.3.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.3.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.3.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.3.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.3.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.4.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.4.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.4.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.4.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.4.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.4.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.5.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.5.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.5.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.5.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.5.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.5.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.6.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.6.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.6.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.6.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.6.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.6.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.7.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.7.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.7.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.7.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.7.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.7.output.LayerNorm.bias\n"
     ]
    }
   ],
   "source": [
    "active = ['classifier.weight', 'classifier.bias', ]\n",
    "for name, param in model.named_parameters():\n",
    "    if name in active:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = True\n",
    "        \n",
    "# freeze first 6 layers of training parameters\n",
    "\n",
    "for name, param in list(model.named_parameters())[:-66]: \n",
    "    print('I will be frozen: {}'.format(name)) \n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.761705Z",
     "iopub.status.idle": "2022-04-11T06:53:02.762413Z",
     "shell.execute_reply": "2022-04-11T06:53:02.762256Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.762235Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# def report(y_true, y_predict):\n",
    "#     acc = balanced_accuracy_score(y_true, y_predict)\n",
    "#     recall = recall_score(y_true, y_predict, average='micro')\n",
    "#     f1 = f1_score(y_true, y_predict, average='micro')\n",
    "#     return acc, recall, f1\n",
    "\n",
    "def report(y_true, y_predict):\n",
    "    labels = set(y_true)\n",
    "    y_predict = [-1 if y not in labels else y for y in y_predict] + [-1]\n",
    "    y_true = list(y_true) + [-1]\n",
    "    \n",
    "    acc = balanced_accuracy_score(y_true, y_predict)\n",
    "    recall = recall_score(y_true, y_predict, average='micro')\n",
    "    f1 = f1_score(y_true, y_predict, average='micro')\n",
    "    return acc, recall, f1\n",
    "\n",
    "def get_loader_params(batch_size):\n",
    "    return {\n",
    "        'batch_size': batch_size,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 0\n",
    "    }\n",
    "\n",
    "class ScoreTracker:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def update(self, loss, y_true, y_pred):\n",
    "        self.total_loss += loss\n",
    "        \n",
    "        acc, recall, f1 = report(y_true, y_pred)\n",
    "        self.acc_total += acc\n",
    "        self.recall_total += recall\n",
    "        self.f1_total += f1\n",
    "        \n",
    "        self.batches += 1\n",
    "        \n",
    "    def reset(self):\n",
    "        self.total_loss = 0.0\n",
    "        self.acc_total = 0.0\n",
    "        self.recall_total = 0.0\n",
    "        self.f1_total = 0.0\n",
    "        self.batches = 0\n",
    "        \n",
    "    def get(self):\n",
    "        return (\n",
    "            self.total_loss / self.batches,\n",
    "            self.acc_total / self.batches,\n",
    "            self.recall_total / self.batches,\n",
    "            self.f1_total / self.batches,\n",
    "        )\n",
    "    \n",
    "    def get_str(self):\n",
    "        values = self.get()\n",
    "        return f\"Averages: Loss {values[0]:.3f} Accuracy: {values[1]:.3f} Recall: {values[2]:.3f} F1-Score: {values[3]:.3f}\"\n",
    "     \n",
    "def compute_model_output(model, batch):\n",
    "    # move batch to GPU\n",
    "    bacth_ids            = batch['ids'].to(device, dtype = torch.long)\n",
    "    batch_attention_mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "    batch_labels         = batch['labels'].to(device, dtype = torch.long)\n",
    "\n",
    "    # loss and probabilities\n",
    "    loss, logits = model(input_ids=bacth_ids, attention_mask=batch_attention_mask, labels=batch_labels).values()\n",
    "\n",
    "    # get predictions (flat)\n",
    "    flattened_labels = batch_labels.view(-1)\n",
    "    active_logits = logits.view(-1, model.num_labels)\n",
    "    flattened_predictions = torch.argmax(active_logits, dim=1)\n",
    "\n",
    "    # exclude uninteresting labels\n",
    "    active_accuracy = batch_labels.view(-1) != EXTRA_LABEL\n",
    "    flattened_labels = torch.masked_select(flattened_labels, active_accuracy)\n",
    "    flattened_predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "    \n",
    "    return loss, flattened_labels, flattened_predictions    \n",
    "\n",
    "def compute_model_prediction(model, batch):    \n",
    "    # move batch to GPU\n",
    "    bacth_ids            = batch['ids'].to(device, dtype = torch.long)\n",
    "    batch_attention_mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "    # probabilities\n",
    "    output = model(input_ids=bacth_ids, attention_mask=batch_attention_mask)\n",
    "    logits = output.logits\n",
    "    \n",
    "    #predictions\n",
    "    predictions = torch.argmax(logits, dim=2)\n",
    "    \n",
    "    return predictions.cpu().numpy()\n",
    "    \n",
    "def train(model, dataset, validation_dataset, train_parameters, epochs, eval_every_n_epochs):\n",
    "    loader_params = get_loader_params(train_parameters['BATCH_SIZE'])\n",
    "    loader = DataLoader(dataset, **loader_params)\n",
    "    optimizer = train_parameters['OPTIMIZER'](params=model.parameters(), lr=train_parameters['LEARNING_RATE'], weight_decay=train_parameters['WEIGHT_DECAY'])\n",
    "    \n",
    "    model.train()\n",
    "    sc = ScoreTracker()\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        sc.reset()\n",
    "        \n",
    "        for i, batch in tqdm(enumerate(loader)):\n",
    "            # zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # model pre\n",
    "            loss, flattened_labels, flattened_predictions = compute_model_output(model, batch)\n",
    "            sc.update(loss.item(), flattened_labels.cpu().numpy(), flattened_predictions.cpu().numpy())\n",
    "            \n",
    "            # gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                parameters=model.parameters(), max_norm=train_parameters['MAX_GRAD_NORM']\n",
    "            )\n",
    "\n",
    "            # backward propagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                    \n",
    "        if (epoch + 1) % eval_every_n_epochs == 0:\n",
    "            print(f\"Train. {sc.get_str()}\")\n",
    "            val_loss, val_acc = evaluate(model, validation_dataset, train_parameters)\n",
    "            model.train()\n",
    "        \n",
    "        train_losses.append(sc.get()[0])\n",
    "        train_accuracies.append(sc.get()[1])\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "    \n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies\n",
    "            \n",
    "def evaluate(model, dataset, evaluate_parameters):\n",
    "    loader_params = get_loader_params(evaluate_parameters['BATCH_SIZE'])\n",
    "    loader = DataLoader(dataset, **loader_params)\n",
    "    \n",
    "    model.eval()\n",
    "    sc = ScoreTracker()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in tqdm(enumerate(loader)):\n",
    "            loss, flattened_labels, flattened_predictions = compute_model_output(model, batch)\n",
    "            sc.update(loss.item(), flattened_labels.cpu().numpy(), flattened_predictions.cpu().numpy())\n",
    "        \n",
    "    print(f\"Evaluate. {sc.get_str()}\")\n",
    "    \n",
    "    return sc.get()[0], sc.get()[1]\n",
    "    \n",
    "def predict(model, dataset, parameters):\n",
    "    batch_size = parameters['BATCH_SIZE']\n",
    "    loader_params = get_loader_params(batch_size)\n",
    "    loader_params['shuffle'] = False\n",
    "    loader = DataLoader(dataset, **loader_params)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in tqdm(enumerate(loader)):\n",
    "            batch_predictions = compute_model_prediction(model, batch)\n",
    "            predictions.extend(batch_predictions)\n",
    "            labels.extend(batch['labels'].cpu().numpy())\n",
    "    \n",
    "    return bert_decode(predictions, map(itemgetter(\"reconstruction\"), dataset)), labels\n",
    "\n",
    "def plot_loss(train_losses, val_losses):\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label='train_loss', color='red')\n",
    "    plt.plot(val_losses, label='val_loss', color='blue')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"output/fig1.jpg\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_acc(train_accuracies, val_accuracies):\n",
    "    plt.figure()\n",
    "    plt.plot(train_accuracies, label='train_accuracy', color='red')\n",
    "    plt.plot(val_accuracies, label='val_accuracy', color='blue')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"output/fig2.jpg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.763259Z",
     "iopub.status.idle": "2022-04-11T06:53:02.763914Z",
     "shell.execute_reply": "2022-04-11T06:53:02.763706Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.763681Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [03:34,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Averages: Loss 1.432 Accuracy: 0.547 Recall: 0.347 F1-Score: 0.347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:16,  9.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.524 Accuracy: 0.835 Recall: 0.614 F1-Score: 0.614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [03:37,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Averages: Loss 0.669 Accuracy: 0.773 Recall: 0.635 F1-Score: 0.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:16,  9.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.367 Accuracy: 0.884 Recall: 0.756 F1-Score: 0.756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [03:40,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Averages: Loss 0.561 Accuracy: 0.811 Recall: 0.700 F1-Score: 0.700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:16,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.323 Accuracy: 0.897 Recall: 0.794 F1-Score: 0.794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [03:43,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Averages: Loss 0.511 Accuracy: 0.831 Recall: 0.728 F1-Score: 0.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:17,  8.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.307 Accuracy: 0.907 Recall: 0.821 F1-Score: 0.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [03:45,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Averages: Loss 0.477 Accuracy: 0.839 Recall: 0.748 F1-Score: 0.748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:16,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.293 Accuracy: 0.914 Recall: 0.836 F1-Score: 0.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [03:41,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Averages: Loss 0.453 Accuracy: 0.846 Recall: 0.758 F1-Score: 0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:16,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.279 Accuracy: 0.915 Recall: 0.845 F1-Score: 0.845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [03:42,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Averages: Loss 0.428 Accuracy: 0.853 Recall: 0.768 F1-Score: 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:16,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.272 Accuracy: 0.922 Recall: 0.856 F1-Score: 0.856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [03:42,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Averages: Loss 0.413 Accuracy: 0.861 Recall: 0.775 F1-Score: 0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:16,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.258 Accuracy: 0.921 Recall: 0.850 F1-Score: 0.850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [03:42,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Averages: Loss 0.394 Accuracy: 0.867 Recall: 0.785 F1-Score: 0.785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:17,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.257 Accuracy: 0.926 Recall: 0.862 F1-Score: 0.862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [03:42,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Averages: Loss 0.382 Accuracy: 0.870 Recall: 0.788 F1-Score: 0.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:17,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.249 Accuracy: 0.926 Recall: 0.867 F1-Score: 0.867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [03:42,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Averages: Loss 0.378 Accuracy: 0.872 Recall: 0.793 F1-Score: 0.793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:17,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.255 Accuracy: 0.927 Recall: 0.871 F1-Score: 0.871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [03:42,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Averages: Loss 0.356 Accuracy: 0.877 Recall: 0.798 F1-Score: 0.798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:17,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.247 Accuracy: 0.929 Recall: 0.874 F1-Score: 0.874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [03:45,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Averages: Loss 0.349 Accuracy: 0.880 Recall: 0.802 F1-Score: 0.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:17,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.247 Accuracy: 0.928 Recall: 0.869 F1-Score: 0.869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [03:42,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Averages: Loss 0.337 Accuracy: 0.883 Recall: 0.807 F1-Score: 0.807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:17,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.240 Accuracy: 0.930 Recall: 0.878 F1-Score: 0.878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [03:44,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Averages: Loss 0.333 Accuracy: 0.884 Recall: 0.807 F1-Score: 0.807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:17,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.233 Accuracy: 0.931 Recall: 0.883 F1-Score: 0.883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [03:44,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Averages: Loss 0.326 Accuracy: 0.887 Recall: 0.812 F1-Score: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:17,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.244 Accuracy: 0.933 Recall: 0.884 F1-Score: 0.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [03:42,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Averages: Loss 0.318 Accuracy: 0.889 Recall: 0.813 F1-Score: 0.813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:16,  9.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.234 Accuracy: 0.937 Recall: 0.887 F1-Score: 0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [03:42,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Averages: Loss 0.321 Accuracy: 0.887 Recall: 0.817 F1-Score: 0.817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:17,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.241 Accuracy: 0.931 Recall: 0.888 F1-Score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [03:42,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Averages: Loss 0.310 Accuracy: 0.889 Recall: 0.817 F1-Score: 0.817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:16,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.240 Accuracy: 0.938 Recall: 0.889 F1-Score: 0.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [03:42,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train. Averages: Loss 0.300 Accuracy: 0.893 Recall: 0.821 F1-Score: 0.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:16,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.236 Accuracy: 0.931 Recall: 0.889 F1-Score: 0.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "parameters = {\n",
    "    \"BATCH_SIZE\": 8,\n",
    "    \"LEARNING_RATE\": 1e-05,\n",
    "    \"WEIGHT_DECAY\": 1e-06,\n",
    "    \"MAX_GRAD_NORM\": 1.0,\n",
    "    \"OPTIMIZER\": torch.optim.AdamW,\n",
    "}\n",
    "\n",
    "train_losses, val_losses, train_accuracies, val_accuracies = train(model, dataset_train, dataset_validation, parameters, 20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(train_losses, val_losses)\n",
    "plot_acc(train_accuracies, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.765246Z",
     "iopub.status.idle": "2022-04-11T06:53:02.765562Z",
     "shell.execute_reply": "2022-04-11T06:53:02.765415Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.765393Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:16,  9.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.236 Accuracy: 0.937 Recall: 0.890 F1-Score: 0.890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:16,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate. Averages: Loss 0.257 Accuracy: 0.930 Recall: 0.888 F1-Score: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2570530753945569, 0.9300241350120962)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, dataset_validation, parameters)\n",
    "evaluate(model, dataset_test, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.766418Z",
     "iopub.status.idle": "2022-04-11T06:53:02.766751Z",
     "shell.execute_reply": "2022-04-11T06:53:02.766579Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.766556Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "303it [00:32,  9.27it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(model, dataset_evaluation, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confustion_matrix(labels, predictions):\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    cmp = ConfusionMatrixDisplay(\n",
    "        confusion_matrix(labels, predictions),\n",
    "        display_labels=label_index.keys(),\n",
    "    )\n",
    "\n",
    "    cmp.plot(ax=ax)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [02:06,  9.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "y_pred, labels = predict(model, dataset_train, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.76848Z",
     "iopub.status.idle": "2022-04-11T06:53:02.768838Z",
     "shell.execute_reply": "2022-04-11T06:53:02.768655Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.768632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116493\n"
     ]
    }
   ],
   "source": [
    "flat_predictions = []\n",
    "for i in range(len(df_evaluation)):\n",
    "    # on some entries something went wrong :P TODO: fix it\n",
    "    if len(y_pred[i]) < len(df_evaluation[\"tokens\"][i]):\n",
    "        y_pred[i] = fixed_sz(y_pred[i], len(df_evaluation[\"tokens\"][i]), 0)\n",
    "        \n",
    "    flat_predictions.extend(y_pred[i])\n",
    "    \n",
    "print(len(flat_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-11T06:53:02.770093Z",
     "iopub.status.idle": "2022-04-11T06:53:02.770449Z",
     "shell.execute_reply": "2022-04-11T06:53:02.770298Z",
     "shell.execute_reply.started": "2022-04-11T06:53:02.770276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653270"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_solution = pd.DataFrame({\"ner_label\": flat_predictions})\n",
    "open(\"output/solution.csv\", \"w\").write('Id' + df_solution.to_csv(index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7557"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
